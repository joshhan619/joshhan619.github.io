<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-09-22T17:13:40+00:00</updated><id>/feed.xml</id><title type="html">Joshua Hanâ€™s Portfolio</title><subtitle>I'm passionate about harnessing artificial intelligence to drive positive global impact. My primary interests lie in computer vision, robotics, and generative AI. Currently, I'm pursuing a Professional Master's in Computer Science at Rice University, where my research focuses on applying transformers to large-scale time series data.</subtitle><entry><title type="html">Krita Image Search</title><link href="/2023/07/25/krita-image-search.html" rel="alternate" type="text/html" title="Krita Image Search" /><published>2023-07-25T16:59:00+00:00</published><updated>2023-07-25T16:59:00+00:00</updated><id>/2023/07/25/krita-image-search</id><content type="html" xml:base="/2023/07/25/krita-image-search.html"><![CDATA[<p>Krita is one of the most popular free and open-source graphics editors for digital art. It is a software that I often use when I draw and it has a lot of interesting features like cutomizable brushes and a whole suite of tools for 2D animation. One of its most appealing qualities is that you can install plugins to enhance your workflow and add new functionality to Krita, of which many are community-developed and free of cost. One of my favorite plugins is <a href="https://github.com/EyeOdin/Pigment.O">Pigment.O</a> which adds a colour wheel with an astonishing amount of customizability.</p>

<h3 id="the-idea">The Idea</h3>
<p>Included in Krita 5.1 by default, you can use the reference image tool to quickly add reference images into Krita from your computer or from your clipboard. When I draw on Krita, I usually spend a significant amount of time choosing the right references. This had led me to have dozens of tabs open on my web browser and multiple 3rd party reference tool applications installed on my computer. My goal was to provide convenient access to a repository of high-quality images to improve my workflow in Krita instead of leaving the application to search for reference images elsewhere.</p>

<h3 id="krita-image-search">Krita Image Search</h3>
<p>Krita Image Search is a Python plugin for Krita that is powered by <a href="https://unsplash.com">Unsplash.com</a>, a photography website with a large library of copyright-free photos. I developed this plugin to fix the problems I had when looking for reference images by creating an intuitive image search interface directly inside Krita. More information about Krita Image Search and how to install it into Krita are on its <a href="https://github.com/joshhan619/krita_image_search">GitHub page</a>.</p>

<p><img src="/assets/images/krita_image_search.png" alt="" /></p>]]></content><author><name></name></author><category term="python" /><category term="art" /><summary type="html"><![CDATA[Krita is one of the most popular free and open-source graphics editors for digital art. It is a software that I often use when I draw and it has a lot of interesting features like cutomizable brushes and a whole suite of tools for 2D animation. One of its most appealing qualities is that you can install plugins to enhance your workflow and add new functionality to Krita, of which many are community-developed and free of cost. One of my favorite plugins is Pigment.O which adds a colour wheel with an astonishing amount of customizability.]]></summary></entry><entry><title type="html">Nothing is FREAKy about Fast Retina Keypoint descriptors</title><link href="/2023/05/11/freak-is-neat.html" rel="alternate" type="text/html" title="Nothing is FREAKy about Fast Retina Keypoint descriptors" /><published>2023-05-11T17:45:14+00:00</published><updated>2023-05-11T17:45:14+00:00</updated><id>/2023/05/11/freak-is-neat</id><content type="html" xml:base="/2023/05/11/freak-is-neat.html"><![CDATA[<p>Recently I have been taking several courses about computer vision in which I was introduced to the many interesting problems and applications of feature detection in images. 
The first feature detection algorithm I learned about was of SIFT (scale-invariant feature transform), which is one of the most commonly used algorithms used for applications like object recognition, panorama stitching, etc.</p>

<p>Although my course stopped at SIFT, with some literature review, I discovered there was a large variety of feature detection algorithms that suggest equal or greater performance than SIFT. Among these algorithms, the one that caught my attention was the FREAK algorithm, which was first proposed by A. Alahi, R. Ortiz, and P. Vandergheynst at the 2012 IEEE Conference on Computer Vision and Pattern Recognition</p>

<h3 id="how-does-freak-work">How does FREAK work?</h3>
<p>Both FREAK and SIFT distinguish features in an image from each other by creating a descriptor for them. You can think of a descriptor as being a mathematical identifier for a feature. Typically we want these descriptors to be rotation invariant and scale invariant so that the same features can be detected in images that are rotated and scaled differently from the original image.</p>

<p>However, whereas SIFT finds features in an image and creates a descriptor them, FREAK only describes them. Another key difference between SIFT and FREAK is that FREAK is a binary descriptor - in other words, the FREAK descriptor is a binary string, which has multiple advantages such as being easier to compare with other feature descriptors (using Hamming distance) and taking up less space.</p>

<p>What makes FREAK special is how it uses a sampling pattern inspired by the anatomy of the human retina. For each feature in the image, we look at a region around the pixel the feature lies in. We apply a Gaussian filter for each receptive field in the sampling pattern, where the sigma value of each Gaussian filter is equal to the radius of the receptive field. To create the FREAK binary descriptor, we need to perform a global training step and then local description steps for each feature.</p>

<p><img src="/assets/images/freak_eye.png" alt="" />
<em>Diagram of the receptive fields of the human retina used in the FREAK descriptor. Source: lahi, Alexandre &amp; Ortiz, Raphael &amp; Vandergheynst, Pierre. (2012). FREAK: Fast retina keypoint. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.</em></p>

<hr />
<p>The goal of the training step is to compute the best pairs of receptive fields that will determine the most important characteristics of a feature. First, we take the values of the Gaussian filters at each receptive field center and compute the differences in intensity for each pair of receptive field centres. In our sampling pattern, we have 43 receptive fields which leads to 903 different combination of pairs. If the difference between a pair is positive, we set one bit in our binary string to 1 and otherwise we set it to 0. Therefore, we get a binary string of 903 bits.</p>

<p>We order the bits from the coursest receptive fields to the finest receptive fields by finding the differences between the larger outermost receptive fields with the smaller innermost receptive fields. After finding the binary strings for each feature, we stack the binary strings on top of each other to make a matrix &gt; D, whose dimensions is n x 903 for n features. Next we compute the mean of each column of D. We pick the columns of D (which correspond to pairs of receptive fields) that have the lowest correlation and thus have a mean value closest to 0.5. After this step, we can choose the best 512 columns that have the least amount of correlation from each other, which determines what our FREAK descriptor will be.</p>

<p>With that, the hardest part is complete. Now we can iterate through each feature and compute its FREAK descriptor based on the best pairs we found in the training step.</p>

<h3 id="investigating-further">Investigating further</h3>
<p>Once I understood how FREAK worked, I wanted to see just how effective it was compared to other feature descriptor algorithms. With my peers Asad Jamil and Matthew Dans, we implemented FREAK in Python from scratch and compared its performance with SIFT and BRISK (another popular binary descriptor). Implementations of SIFT and BRISK were taken from the OpenCV-Python library. The results of the investigation and a writeup of our findings can be seen <a href="https://github.com/joshhan619/freak">here</a>.</p>]]></content><author><name></name></author><category term="computer_vision" /><category term="research" /><summary type="html"><![CDATA[Recently I have been taking several courses about computer vision in which I was introduced to the many interesting problems and applications of feature detection in images. The first feature detection algorithm I learned about was of SIFT (scale-invariant feature transform), which is one of the most commonly used algorithms used for applications like object recognition, panorama stitching, etc.]]></summary></entry></feed>