[
    {
      "title": "Implementation and Analysis of Fast Retina Keypoint (FREAK) descriptor algorithm",
      "pagename": "/freak",
      "text": "<p>Recently I have been taking several courses about computer vision in which I was introduced to the many interesting problems and applications of feature detection in images. The first feature detection algorithm I learned about was of SIFT (scale-invariant feature transform), which is one of the most commonly used algorithms used for applications like object recognition, panorama stitching, etc. Although my course stopped at SIFT, with some literature review, I discovered there was a large variety of feature detection algorithms that suggest equal or greater performance than SIFT. Among these algorithms, the one that caught my attention was the FREAK algorithm, which was first proposed by A. Alahi, R. Ortiz, and P. Vandergheynst at the 2012 IEEE Conference on Computer Vision and Pattern Recognition.<br /><\/p><h3>How does FREAK work?<\/h3><p>Both FREAK and SIFT distinguish features in an image from each other by creating a descriptor for them. You can think of a descriptor as being a mathematical &quot;ID&quot; for a feature. Typically we want these descriptors to be rotation invariant and scale invariant so the same feature can be detected in images that are rotated and scaled differently from the original image. However, whereas SIFT finds features in an image and creates a descriptor them, FREAK only describes them. Another key difference between SIFT and FREAK is that FREAK is a binary descriptor - in other words, the FREAK descriptor is a binary string, which has multiple advantages such as being easier to compare with other feature descriptors (using Hamming distance) and taking up less space.</p><p>What makes FREAK special is how it uses a sampling pattern inspired by the anatomy of the human retina. For each feature in the image, we look at a region around the pixel the feature lies in. We apply a Gaussian filter for each receptive field in the sampling pattern, where the sigma value of each Gaussian filter is equal to the radius of the receptive field. To create the FREAK binary descriptor, we need to perform a global training step and then local description steps for each feature.<\/p><p>The goal of the training step is to compute the best pairs of receptive fields that will determine the most important characteristics of a feature. First, we take the values of the Gaussian filters at each receptive field center and compute the differences in intensity for each pair of receptive field centres. In our sampling pattern, we have 43 receptive fields which leads to 903 different combination of pairs. If the difference between a pair is positive, we set one bit in our binary string to 1 and otherwise we set it to 0. Therefore, we get a binary string of 903 bits. We order the bits with a &quot;course to fine&quot; ordering where we find the differences between the larger outermost receptive fields with the smaller innermost receptive fields. After finding the binary strings for each feature, we stack the binary strings on top of each other to make a matrix D, whose dimensions is n x 903 for n features. Next we compute the mean of each column of D. We pick the columns of D (which correspond to pairs of receptive fields) that have the lowest correlation and thus have a mean value closest to 0.5. After this step, we can choose the best 512 columns that have the least amount of correlation from each other, which determines what our FREAK descriptor will be.<\/p><p>In the descriptor step, we iterate through each feature and compute its FREAK descriptor based on the best pairs we found in the training step.<\/p><h3>Investigating further<\/h3><p>Once I understood how FREAK worked, I wanted to see just how effective it was compared to other feature descriptor algorithms. With my peers Asad Jamil and Matthew Dans, we implemented FREAK in Python from scratch and compared its performance with SIFT and BRISK (another binary descriptor). Implementations of SIFT and BRISK were taken from the OpenCV-Python library. The results of the investigation and a writeup of our findings can be seen at <a href=https://github.com/joshhan619/freak>this repository<\/a>.<\/p>"
    },
    {
      "title": "Phonogenesis Quiz Platform for Teachers and Students.",
      "pagename": "/phonogenesis-quiz",
      "text": "Pellentesque elementum libero nec ligula accumsan ornare. Donec non volutpat nunc. Nunc eget dapibus orci. Sed convallis, nisl et lacinia pharetra, est sapien egestas orci, nec sollicitudin tortor turpis id orci. Vivamus congue semper ipsum, et ornare nibh accumsan a. Suspendisse nec gravida est. Nullam scelerisque, erat at imperdiet blandit, libero tortor luctus eros, sed tincidunt odio leo eget leo. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Nunc rhoncus magna in ante mattis sodales. Nulla facilisi. Etiam sed eros vestibulum, maximus leo fringilla, tempus est. Integer rutrum mauris vel orci pharetra luctus. Curabitur laoreet interdum urna. Sed interdum, risus eu gravida pulvinar, nisi mi molestie tortor, eget varius metus risus at risus. Maecenas tristique arcu sit amet ex tincidunt consectetur. Morbi sed ligula erat. Suspendisse venenatis aliquam lorem sed venenatis. Aliquam ac velit quam. Phasellus feugiat aliquam tempor. Morbi in nisi non metus interdum elementum et non turpis. Pellentesque sit amet lacus ut nunc iaculis consequat. Aenean eu erat bibendum sapien aliquet finibus. Morbi sed turpis vitae odio egestas accumsan quis non arcu. Praesent aliquam mauris non varius ultrices. Donec dignissim sodales tortor, non tincidunt odio congue ut. Donec varius pulvinar pharetra. Donec sollicitudin quam quam, eu tincidunt ex hendrerit rhoncus. Curabitur luctus ut libero eget pulvinar. Donec at est auctor, posuere leo id, porta lorem. Donec fermentum ex vel sodales pretium. Phasellus sodales sagittis quam, ut accumsan tortor ultricies id. Integer consequat sagittis eleifend. Praesent iaculis tortor et neque pulvinar, nec semper urna condimentum."
    }
]
